# Image-Colorization-Using-Conditional-GANs


Image Colorization Using Conditional GANs

This project aims to colorize grayscale images using Conditional Generative Adversarial Networks (GANs). The model consists of a U-Net based generator and a discriminator designed to distinguish between real and generated images. The approach leverages binary cross-entropy loss, adversarial loss, and SSIM loss to produce realistic colorized images.

Architecture

Generator

	•	The generator is based on a U-Net model, which has proven effective in tasks requiring high-quality image generation.
	•	Number of filters per layer: [64, 128, 256, 512, 512, 512, 512]
	•	The U-Net architecture helps in capturing both local and global features of the input image by combining encoder and decoder paths.

Discriminator

	•	The discriminator is designed to classify images as either real (color) or fake (generated by the model).
	•	Number of filters per layer: [64, 128, 256, 512]
	•	The discriminator improves the quality of generated images by forcing the generator to produce images that are more similar to real ones.

Loss Functions

	•	Binary Cross-Entropy Loss: Measures the difference between the predicted and actual labels, used for both the generator and discriminator.
	•	Adversarial Loss: Ensures the generator produces images that can fool the discriminator.
	•	SSIM Loss: Structural Similarity Index (SSIM) loss is used to ensure that the generated images have a structure similar to that of the input grayscale images.

Getting Started

Prerequisites

	•	Python 3.7 or above
	•	TensorFlow 2.x
	•	NumPy
	•	OpenCV


